{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple customer care bot\n",
    "responses = {\n",
    "      \"hi\": \"Hello! Welcome to TechGadget Support. How can I assist you today?\",\n",
    "      \"do you have smartwatches\": \"Yes, we have a variety of smartwatches. You can check them out on our products page.\",\n",
    "      \"shipping time\": \"Shipping usually takes 3-5 business days.\",\n",
    "      \"shipping methods\": \"We offer standard, expedited, and overnight shipping.\",\n",
    "      \"return policy\": \"You can return products within 30 days of receipt for a full refund.\",\n",
    "      \"how to return\": \"To return a product, please visit our returns page for a step-by-step guide.\",\n",
    "      \"won't turn on\": \"Make sure your gadget is charged. If it still won't turn on, you can visit our troubleshooting page.\",\n",
    "      \"reset device\": \"To reset your device, hold down the power button for 10 seconds. If that doesn't work, please check the manual for a factory reset.\",\n",
    "      \"bye\": \"Thank you for visiting TechGadget. If you have more questions, feel free to ask. Goodbye!\"\n",
    "}\n",
    "\n",
    "def get_bot_response(user_input):\n",
    "      user_input = user_input.lower()\n",
    "\n",
    "      for keyword, response in responses.items():\n",
    "          if keyword in user_input:\n",
    "              return response\n",
    "\n",
    "      return \"I'm not sure how to respond to that. Can you try asking something else?\"\n",
    "\n",
    "while True:\n",
    "      user_input = input(\"You: \")\n",
    "      if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "          print(\"Bot: Goodbye! If you have any more questions, we're here to help.\")\n",
    "          break\n",
    "\n",
    "      response = get_bot_response(user_input)\n",
    "      print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591dc80",
   "metadata": {},
   "source": [
    "In this exercise, you will complete two machine learning tasks using the Jupyter Notebook below.\n",
    "\n",
    "Supervised learning\n",
    "Unsupervised learning\n",
    "You'll generate synthetic data for both exercises and execute them in the Jupyter Notebook. Copy the code below on this page and paste it into a notebook cell, then run the cell.\n",
    "\n",
    "Part 1: Predicting Building Energy Efficiency (Supervised Learning)\n",
    "Scenario - You are working for an architecture firm, and your task is to build a model that predicts the energy efficiency rating of buildings based on features like wall area, roof area, overall height, etc.\n",
    "\n",
    "Supervised Learning Code: To predict the energy efficiency of buildings.\n",
    "\n",
    "Note - These exercises use synthetic data for simplicity and demonstration purposes. In real-world applications, actual data and more complex models might be used. The choice of algorithms - RandomForestRegressor for supervised learning and KMeans for unsupervised learning - is based on their general applicability and ease of understanding for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037aa849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Generate synthetic dataset for building features and energy efficiency ratings\n",
    "np.random.seed(0)\n",
    "data_size = 500\n",
    "data = {\n",
    "    'WallArea': np.random.randint(200, 400, data_size),\n",
    "    'RoofArea': np.random.randint(100, 200, data_size),\n",
    "    'OverallHeight': np.random.uniform(3, 10, data_size),\n",
    "    'GlazingArea': np.random.uniform(0, 1, data_size),\n",
    "    'EnergyEfficiency': np.random.uniform(10, 50, data_size)  # Energy efficiency rating\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Data preprocessing\n",
    "X = df.drop('EnergyEfficiency', axis=1)\n",
    "y = df['EnergyEfficiency']\n",
    "\n",
    "# Visualize the relationships between features and the target variable (Energy Efficiency)\n",
    "sns.pairplot(df, x_vars=['WallArea', 'RoofArea', 'OverallHeight', 'GlazingArea'], y_vars='EnergyEfficiency', height=4, aspect=1, kind='scatter')\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Plot the True values vs Predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(\"True Values vs Predicted Values\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd12039",
   "metadata": {},
   "source": [
    "Part 2: Vehicle Clustering (Unsupervised Learning)\n",
    "Scenario - You are working for an automotive company, and your task is to cluster vehicles into groups based on their features such as weight, engine size, and horsepower.\n",
    "\n",
    "Unsupervised Learning Code: To cluster vehicles based on their specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Generate synthetic dataset for vehicles\n",
    "np.random.seed(0)\n",
    "data_size = 300\n",
    "data = {\n",
    "    'Weight': np.random.randint(1000, 3000, data_size),\n",
    "    'EngineSize': np.random.uniform(1.0, 4.0, data_size),\n",
    "    'Horsepower': np.random.randint(50, 300, data_size)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# No labels are needed for unsupervised learning\n",
    "X = df\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Plotting the clusters\n",
    "plt.scatter(df['Weight'], df['Horsepower'], c=kmeans.labels_)\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Horsepower')\n",
    "plt.title('Vehicle Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a361e5",
   "metadata": {},
   "source": [
    "Building a Decision Tree to Predict Customer Churn\n",
    "Imagine you are a data analyst at a telecom company. The marketing department has noticed an increase in customer churn and needs your help to identify which customers are most likely to leave next month.\n",
    "\n",
    "Your Tasks\n",
    "In this exercise, you will build a decision tree model to predict customer churn for a telecom company. Customer churn refers to when a customer stops doing business with a company. Predicting churn is crucial for businesses to retain customers by addressing their issues proactively.\n",
    "\n",
    "Copy the code below on this page and paste it into a notebook cell in the Jupyter Notebook below, then run the cell\n",
    "Dataset Description\n",
    "We will use a synthetic dataset for this exercise. The dataset contains the following columns:\n",
    "\n",
    "CustomerID: A unique identifier for each customer.\n",
    "Age: The age of the customer.\n",
    "MonthlyCharge: The monthly bill amount for the customer.\n",
    "CustomerServiceCalls: The number of times the customer contacted customer service.\n",
    "Churn: This is our target variable, indicating whether the customer churned (Yes) or not (No).\n",
    "Step-by-Step Instructions\n",
    "Setup the Environment:\n",
    "Import necessary libraries: Pandas for data manipulation, Scikit-learn for machine learning, and Matplotlib for visualization.\n",
    "Create the Dataset:\n",
    "Use Python to create a synthetic dataset. We'll make a small dataset for simplicity.\n",
    "Data Preparation:\n",
    "Split the data into features (X) and the target variable (y).\n",
    "Further split the dataset into training and testing sets.\n",
    "Build the Decision Tree Model:\n",
    "Use Scikit-learn to create a DecisionTreeClassifier.\n",
    "Train the model on the training data.\n",
    "Evaluate the Model:\n",
    "Make predictions on the test set.\n",
    "Calculate the accuracy of the model.\n",
    "Visualize the Decision Tree:\n",
    "Use Matplotlib to visualize how the decision tree makes decisions.\n",
    "Discuss the Results:\n",
    "Interpret the decision tree.\n",
    "Discuss how it can be used by the company to reduce customer churn.\n",
    "Python Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Creating a synthetic dataset\n",
    "# This dataset simulates customer data for a telecom company\n",
    "data = {\n",
    "      'CustomerID': range(1, 101),  # Unique ID for each customer\n",
    "      'Age': [20, 25, 30, 35, 40, 45, 50, 55, 60, 65]*10,  # Age of customers\n",
    "      'MonthlyCharge': [50, 60, 70, 80, 90, 100, 110, 120, 130, 140]*10,  # Monthly bill amount\n",
    "      'CustomerServiceCalls': [1, 2, 3, 4, 0, 1, 2, 3, 4, 0]*10,  # Number of customer service calls\n",
    "      'Churn': ['No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes']*10  # Churn status\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Splitting the dataset into features and target variable\n",
    "# Features include age, monthly charge, and customer service calls\n",
    "# The target variable is churn (Yes or No)\n",
    "X = df[['Age', 'MonthlyCharge', 'CustomerServiceCalls']]\n",
    "y = df['Churn']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "# 70% of the data is used for training and 30% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Decision Tree model\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluating the model using accuracy\n",
    "# Accuracy is the proportion of correct predictions among the total number of cases processed\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy}')\n",
    "\n",
    "# Visualizing the decision tree\n",
    "# This visualization helps in understanding how the model makes decisions\n",
    "plt.figure(figsize=(12,8))\n",
    "tree.plot_tree(clf, filled=True, feature_names=['Age', 'MonthlyCharge', 'CustomerServiceCalls'], class_names=['No Churn', 'Churn'])\n",
    "plt.title('Decision Tree for Predicting Customer Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec75c5",
   "metadata": {},
   "source": [
    "When you visualize a decision tree, especially one created using Scikit-learn's DecisionTreeClassifier, you'll notice several terms on each node of the tree. Understanding these terms is crucial for interpreting the tree's decision-making process. Let's break down each of these terms:\n",
    "\n",
    "Gini\n",
    "The Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset.\n",
    "The Gini impurity ranges from 0 to 0.5, where 0 indicates that all elements in the subset belong to the same class (perfect purity), and 0.5 means the data is randomly distributed across various classes.\n",
    "In decision trees, a lower Gini impurity is generally preferred as it indicates greater purity of the node.\n",
    "Samples\n",
    "This value represents the number of samples (or records) that reach the node.\n",
    "It gives an idea of how much of the training data is affected by the conditions leading to this node.\n",
    "A high number of samples in a node means that the condition or rule associated with that node is relevant for a significant portion of the dataset.\n",
    "Value\n",
    "This shows the distribution of the samples in different classes at that particular node.\n",
    "For a binary classification problem (like churn prediction with 'Yes' or 'No'), the value is presented as a list of two numbers. The first number indicates the count of samples in the first class, and the second number indicates the count of samples in the second class.\n",
    "This distribution helps in understanding which class is predominant at a particular node.\n",
    "Class\n",
    "This indicates the class that would be predicted if the decision tree traversal ends at that node.\n",
    "It is determined based on the majority class of the samples that reach the node. For instance, if most samples at a node belong to the 'No Churn' class, the node will predict 'No Churn'.\n",
    "Feature Name (e.g., 'Monthly Charge')\n",
    "This is not a standard part of the decision tree node description, but it may appear in the tree's branches.\n",
    "It represents the feature (or attribute) used to split the data at that node.\n",
    "For example, if you see \"MonthlyCharge <= 80\", it means that the tree is splitting the data at this node based on whether the monthly charge is less than or equal to 80.\n",
    "Understanding these components is essential for interpreting how the decision tree makes its predictions and which features are influential in the decision-making process. This can provide valuable insights, especially in business contexts like customer churn prediction.\n",
    "\n",
    "Remember to delete the notebook instance after reviewing the solution.\n",
    "\n",
    "\n",
    "This exercise covered several key terms and concepts related to machine learning, particularly focusing on the process of training and testing a decision tree model.\n",
    "\n",
    "Key Concepts\n",
    "Splitting the Dataset - The dataset is divided into training and testing sets. Typically, 70% of the data is used for training the model, and the remaining 30% is reserved for testing.\n",
    "\n",
    "Training Data vs. Testing Data - Training data is used to train the machine learning model. In contrast, testing data, which the model has not seen during training, is used to evaluate the model's performance and generalization ability.\n",
    "\n",
    "Model Training Process - The process involves using a 'fit' method where the model is trained using features (X_train) and targets (Y_train). The testing data is not used in this stage.\n",
    "\n",
    "Prediction and Accuracy Assessment - After training, the model makes predictions on the test data (X_test). These predictions are then compared with the actual outcomes (Y_test) to calculate the model's accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5920d",
   "metadata": {},
   "source": [
    "For this exercise, you will create a simple neural network example. We'll use a synthetic dataset to predict whether a customer will make a purchase based on two features:\n",
    "\n",
    "Website visit duration\n",
    "Number of pages visited.\n",
    "This is a binary classification problem, and we'll use a small neural network for quick execution. Copy and paste the code into the Jupyter Notebook below. Place each step of code into it's own cell, then execute each cell in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "210c0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Generating synthetic data\n",
    "np.random.seed(0)\n",
    "data_size = 200\n",
    "features = np.random.rand(data_size, 2)  # Two features: visit duration and pages visited\n",
    "labels = (features[:, 0] + features[:, 1] > 1).astype(int)  # Purchase (1) or not (0)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(features, columns=['VisitDuration', 'PagesVisited'])\n",
    "df['Purchase'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "830ef99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['VisitDuration', 'PagesVisited']], df['Purchase'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e491758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6840  \n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5513 - loss: 0.6705 \n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6288 - loss: 0.6609 \n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6225 - loss: 0.6642 \n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6607 - loss: 0.6561 \n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.6462 \n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.6383 \n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.6340 \n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.6330 \n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.6250 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1654e3657d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(2,)),  # Input layer with 2 features\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "576e9945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8042 - loss: 0.6042 \n",
      "Test Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf5f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
